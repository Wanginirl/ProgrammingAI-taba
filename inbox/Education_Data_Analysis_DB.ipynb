{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education Data Analysis with Database Integration\n",
    "\n",
    "This notebook presents a comprehensive analysis of education data across different countries, with data stored and analyzed using both PostgreSQL and MongoDB databases.\n",
    "\n",
    "## Project Components\n",
    "1. Database Setup and Configuration\n",
    "2. Data Collection and Storage\n",
    "3. Data Analysis\n",
    "4. Time Series Forecasting\n",
    "5. Visualization\n",
    "\n",
    "## Prerequisites\n",
    "- PostgreSQL database\n",
    "- MongoDB database\n",
    "- Required Python packages\n",
    "\n",
    "First, ensure that both PostgreSQL and MongoDB are running using Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Docker containers are running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Install required packages and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy plotly scikit-learn statsmodels pymongo psycopg2-binary python-dotenv eurostat tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import eurostat\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='education_data_collection.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Configuration\n",
    "\n",
    "Set up connections to PostgreSQL and MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# PostgreSQL configuration\n",
    "POSTGRES_CONFIG = {\n",
    "    'dbname': os.getenv('POSTGRES_DB', 'education_db'),\n",
    "    'user': os.getenv('POSTGRES_USER', 'postgres'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'postgrespassword'),\n",
    "    'host': os.getenv('POSTGRES_HOST', 'localhost'),\n",
    "    'port': os.getenv('POSTGRES_PORT', '5432')\n",
    "}\n",
    "\n",
    "# MongoDB configuration\n",
    "MONGODB_CONFIG = {\n",
    "    'host': os.getenv('MONGO_HOST', 'localhost'),\n",
    "    'port': int(os.getenv('MONGO_PORT', '27017')),\n",
    "    'db': os.getenv('MONGO_DB', 'education_db')\n",
    "}\n",
    "\n",
    "# Test database connections\n",
    "try:\n",
    "    # PostgreSQL connection\n",
    "    pg_conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "    print(\"Successfully connected to PostgreSQL\")\n",
    "    \n",
    "    # MongoDB connection\n",
    "    mongo_client = MongoClient(MONGODB_CONFIG['host'], MONGODB_CONFIG['port'])\n",
    "    mongo_db = mongo_client[MONGODB_CONFIG['db']]\n",
    "    print(\"Successfully connected to MongoDB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to databases: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Schema Setup\n",
    "\n",
    "Create necessary tables in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_postgres_schema(conn):\n",
    "    \"\"\"Set up PostgreSQL database schema\"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Create tables for raw data\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS raw_education_data (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    country VARCHAR(50),\n",
    "                    year INTEGER,\n",
    "                    metric_name VARCHAR(50),\n",
    "                    metric_value FLOAT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "\n",
    "                CREATE TABLE IF NOT EXISTS analysis_results (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    analysis_type VARCHAR(50),\n",
    "                    metric_name VARCHAR(50),\n",
    "                    year INTEGER,\n",
    "                    country VARCHAR(50),\n",
    "                    result_value FLOAT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "\n",
    "                CREATE TABLE IF NOT EXISTS forecasts (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    metric_name VARCHAR(50),\n",
    "                    forecast_year INTEGER,\n",
    "                    forecast_value FLOAT,\n",
    "                    confidence_lower FLOAT,\n",
    "                    confidence_upper FLOAT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            conn.commit()\n",
    "            print(\"PostgreSQL schema setup completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up PostgreSQL schema: {str(e)}\")\n",
    "\n",
    "# Set up schema\n",
    "setup_postgres_schema(pg_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Collection and Storage\n",
    "\n",
    "Collect education data from Eurostat and store in databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_store_education_data(pg_conn, mongo_db):\n",
    "    \"\"\"Collect education data from Eurostat and store in databases\"\"\"\n",
    "    datasets = {\n",
    "        'education_investment': 'educ_uoe_fine09',\n",
    "        'student_teacher_ratio': 'educ_uoe_perp04',\n",
    "        'completion_rate': 'edat_lfse_03',\n",
    "        'literacy_rate': 'edat_lfse_01'\n",
    "    }\n",
    "    \n",
    "    for metric, code in datasets.items():\n",
    "        try:\n",
    "            print(f\"Collecting {metric} data...\")\n",
    "            df = eurostat.get_data_df(code)\n",
    "            \n",
    "            # Process data\n",
    "            if 'geo\\\\TIME_PERIOD' in df.columns:\n",
    "                df[['country', 'year']] = df['geo\\\\TIME_PERIOD'].str.split('\\\\', expand=True)\n",
    "                df = df.drop('geo\\\\TIME_PERIOD', axis=1)\n",
    "            \n",
    "            # Transform to long format\n",
    "            year_columns = [col for col in df.columns if col.isdigit()]\n",
    "            id_vars = [col for col in df.columns if not col.isdigit()]\n",
    "            \n",
    "            df_long = df.melt(\n",
    "                id_vars=id_vars,\n",
    "                value_vars=year_columns,\n",
    "                var_name='year',\n",
    "                value_name=metric\n",
    "            )\n",
    "            \n",
    "            # Store in PostgreSQL\n",
    "            with pg_conn.cursor() as cur:\n",
    "                values = [(\n",
    "                    row['country'],\n",
    "                    int(row['year']),\n",
    "                    metric,\n",
    "                    float(row[metric]) if pd.notnull(row[metric]) else None\n",
    "                ) for _, row in df_long.iterrows()]\n",
    "                \n",
    "                execute_values(cur, \"\"\"\n",
    "                    INSERT INTO raw_education_data (country, year, metric_name, metric_value)\n",
    "                    VALUES %s\n",
    "                    ON CONFLICT (country, year, metric_name) \n",
    "                    DO UPDATE SET metric_value = EXCLUDED.metric_value;\n",
    "                \"\"\", values)\n",
    "            pg_conn.commit()\n",
    "            \n",
    "            # Store in MongoDB\n",
    "            collection = mongo_db[metric]\n",
    "            records = df_long.to_dict('records')\n",
    "            for record in records:\n",
    "                collection.update_one(\n",
    "                    {'country': record['country'], 'year': record['year']},\n",
    "                    {'$set': record},\n",
    "                    upsert=True\n",
    "                )\n",
    "            \n",
    "            print(f\"Successfully stored {metric} data\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric} data: {str(e)}\")\n",
    "\n",
    "# Collect and store data\n",
    "collect_and_store_education_data(pg_conn, mongo_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Analysis\n",
    "\n",
    "Analyze education metrics from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_education_metrics(pg_conn, metric_name):\n",
    "    \"\"\"Analyze education metrics from PostgreSQL database\"\"\"\n",
    "    try:\n",
    "        with pg_conn.cursor() as cur:\n",
    "            # Calculate basic statistics\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    year,\n",
    "                    AVG(metric_value) as mean_value,\n",
    "                    STDDEV(metric_value) as std_value,\n",
    "                    MIN(metric_value) as min_value,\n",
    "                    MAX(metric_value) as max_value\n",
    "                FROM raw_education_data\n",
    "                WHERE metric_name = %s\n",
    "                GROUP BY year\n",
    "                ORDER BY year;\n",
    "            \"\"\", (metric_name,))\n",
    "            \n",
    "            results = cur.fetchall()\n",
    "            stats_df = pd.DataFrame(results, \n",
    "                                  columns=['year', 'mean', 'std', 'min', 'max'])\n",
    "            \n",
    "            # Create visualizations\n",
    "            trend_fig = px.line(stats_df, x='year', y='mean',\n",
    "                              title=f'{metric_name} Trend Over Time')\n",
    "            trend_fig.show()\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"\\nStatistics for {metric_name}:\")\n",
    "            print(stats_df)\n",
    "            \n",
    "            return stats_df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {metric_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Analyze each metric\n",
    "metrics = ['education_investment', 'student_teacher_ratio', \n",
    "          'completion_rate', 'literacy_rate']\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\nAnalyzing {metric}...\")\n",
    "    analyze_education_metrics(pg_conn, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Forecasting\n",
    "\n",
    "Forecast future values for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_metric(pg_conn, metric_name, periods=5):\n",
    "    \"\"\"Forecast future values for a metric\"\"\"\n",
    "    try:\n",
    "        with pg_conn.cursor() as cur:\n",
    "            # Get historical data\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT year, AVG(metric_value) as avg_value\n",
    "                FROM raw_education_data\n",
    "                WHERE metric_name = %s\n",
    "                GROUP BY year\n",
    "                ORDER BY year\n",
    "            \"\"\", (metric_name,))\n",
    "            \n",
    "            results = cur.fetchall()\n",
    "            historical_df = pd.DataFrame(results, columns=['year', 'value'])\n",
    "            \n",
    "            # Fit SARIMA model\n",
    "            model = SARIMAX(historical_df['value'], \n",
    "                          order=(1, 1, 1), \n",
    "                          seasonal_order=(1, 1, 1, 12))\n",
    "            results = model.fit()\n",
    "            \n",
    "            # Generate forecast\n",
    "            forecast = results.forecast(periods)\n",
    "            \n",
    "            # Create visualization\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x=historical_df['year'], \n",
    "                                   y=historical_df['value'],\n",
    "                                   name='Historical'))\n",
    "            fig.add_trace(go.Scatter(x=range(historical_df['year'].max() + 1, \n",
    "                                            historical_df['year'].max() + periods + 1),\n",
    "                                   y=forecast,\n",
    "                                   name='Forecast'))\n",
    "            fig.update_layout(title=f'{metric_name} Forecast')\n",
    "            fig.show()\n",
    "            \n",
    "            print(f\"\\nForecast values for {metric_name}:\")\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'year': range(historical_df['year'].max() + 1, \n",
    "                             historical_df['year'].max() + periods + 1),\n",
    "                'forecast': forecast\n",
    "            })\n",
    "            print(forecast_df)\n",
    "            \n",
    "            return forecast_df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error forecasting {metric_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Generate forecasts for each metric\n",
    "for metric in metrics:\n",
    "    print(f\"\\nForecasting {metric}...\")\n",
    "    forecast_metric(pg_conn, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup\n",
    "\n",
    "Close database connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connections\n",
    "if pg_conn:\n",
    "    pg_conn.close()\n",
    "    print(\"PostgreSQL connection closed\")\n",
    "    \n",
    "if mongo_db:\n",
    "    mongo_db.client.close()\n",
    "    print(\"MongoDB connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
