{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education Data Analysis Project\n",
    "\n",
    "## Overview\n",
    "This notebook presents a comprehensive analysis of education data across different countries. The project combines data from various sources to analyze education investment, quality, outcomes, and resource allocation patterns.\n",
    "\n",
    "### Project Objectives\n",
    "1. Analyze education investment trends\n",
    "2. Evaluate education quality indicators\n",
    "3. Assess resource allocation efficiency\n",
    "4. Predict future education metrics\n",
    "\n",
    "### Analysis Components\n",
    "- Data collection from Eurostat\n",
    "- Data storage in PostgreSQL and MongoDB\n",
    "- Statistical analysis\n",
    "- Time series forecasting\n",
    "- Interactive visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's install and import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: plotly in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (5.24.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: statsmodels in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (0.14.4)\n",
      "Requirement already satisfied: pymongo in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (4.6.0)\n",
      "Requirement already satisfied: psycopg2-binary in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.9.10)\n",
      "Requirement already satisfied: python-dotenv in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: eurostat in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from plotly) (24.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pymongo) (2.6.1)\n",
      "Requirement already satisfied: requests in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from eurostat) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy plotly scikit-learn statsmodels pymongo psycopg2-binary python-dotenv eurostat tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pymongo\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import eurostat\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Configuration\n",
    "\n",
    "Set up connections to PostgreSQL and MongoDB databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# PostgreSQL configuration\n",
    "POSTGRES_CONFIG = {\n",
    "    'dbname': os.getenv('POSTGRES_DB', 'education_db'),\n",
    "    'user': os.getenv('POSTGRES_USER', 'postgres'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'postgrespassword'),\n",
    "    'host': os.getenv('POSTGRES_HOST', 'localhost'),\n",
    "    'port': os.getenv('POSTGRES_PORT', '5432')\n",
    "}\n",
    "\n",
    "# MongoDB configuration\n",
    "MONGODB_CONFIG = {\n",
    "    'host': os.getenv('MONGODB_HOST', 'localhost'),\n",
    "    'port': int(os.getenv('MONGODB_PORT', '27017')),\n",
    "    'db': os.getenv('MONGODB_DB', 'education_db')\n",
    "}\n",
    "\n",
    "# Create database connections\n",
    "def get_postgres_connection():\n",
    "    return psycopg2.connect(**POSTGRES_CONFIG)\n",
    "\n",
    "def get_mongodb_connection():\n",
    "    client = pymongo.MongoClient(host=MONGODB_CONFIG['host'], port=MONGODB_CONFIG['port'])\n",
    "    return client[MONGODB_CONFIG['db']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Collection\n",
    "\n",
    "Collect education data from Eurostat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_education_data():\n",
    "    # Eurostat dataset codes\n",
    "    datasets = {\n",
    "        'education_investment': 'educ_uoe_fine09',\n",
    "        'student_teacher_ratio': 'educ_uoe_perp04',\n",
    "        'completion_rate': 'edat_lfse_03',\n",
    "        'literacy_rate': 'edat_lfse_01'\n",
    "    }\n",
    "    \n",
    "    data = {}\n",
    "    for metric, code in datasets.items():\n",
    "        try:\n",
    "            df = eurostat.get_data_df(code)\n",
    "            data[metric] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting {metric} data: {str(e)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Collect data\n",
    "education_data = collect_education_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Clean and prepare the collected data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting education data...\n",
      "Collecting education_investment data...\n",
      "\n",
      "Columns for education_investment:\n",
      "['freq', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Collecting student_teacher_ratio data...\n",
      "\n",
      "Columns for student_teacher_ratio:\n",
      "['freq', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
      "Collecting completion_rate data...\n",
      "\n",
      "Columns for completion_rate:\n",
      "['freq', 'sex', 'age', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Collecting literacy_rate data...\n",
      "\n",
      "Columns for literacy_rate:\n",
      "['freq', 'sex', 'wstatus', 'citizen', 'age', 'unit', 'geo\\\\TIME_PERIOD', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Processing education_investment data...\n",
      "Columns in education_investment dataset:\n",
      "['index', 'freq', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Warning: No identifying columns found in education_investment dataset\n",
      "\n",
      "Processing student_teacher_ratio data...\n",
      "Columns in student_teacher_ratio dataset:\n",
      "['index', 'freq', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
      "Warning: No identifying columns found in student_teacher_ratio dataset\n",
      "\n",
      "Processing completion_rate data...\n",
      "Columns in completion_rate dataset:\n",
      "['index', 'freq', 'sex', 'age', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Warning: No identifying columns found in completion_rate dataset\n",
      "\n",
      "Processing literacy_rate data...\n",
      "Columns in literacy_rate dataset:\n",
      "['index', 'freq', 'sex', 'wstatus', 'citizen', 'age', 'unit', 'geo\\\\TIME_PERIOD', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Warning: No identifying columns found in literacy_rate dataset\n",
      "\n",
      "Processed data structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n",
      "None\n",
      "\n",
      "First few rows of processed data:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "def collect_education_data():\n",
    "    # Eurostat dataset codes for different education metrics\n",
    "    datasets = {\n",
    "        'education_investment': 'educ_uoe_fine09',\n",
    "        'student_teacher_ratio': 'educ_uoe_perp04',\n",
    "        'completion_rate': 'edat_lfse_03',\n",
    "        'literacy_rate': 'edat_lfse_01'\n",
    "    }\n",
    "    \n",
    "    data = {}\n",
    "    for metric, code in datasets.items():\n",
    "        try:\n",
    "            print(f\"Collecting {metric} data...\")\n",
    "            df = eurostat.get_data_df(code)\n",
    "            # Print data structure to understand column names\n",
    "            print(f\"\\nColumns for {metric}:\")\n",
    "            print(df.columns.tolist())\n",
    "            data[metric] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting {metric} data: {str(e)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_data(data):\n",
    "    processed_data = pd.DataFrame()\n",
    "    \n",
    "    for metric, df in data.items():\n",
    "        print(f\"\\nProcessing {metric} data...\")\n",
    "        \n",
    "        # Reset index to keep original index as columns\n",
    "        df = df.reset_index()\n",
    "        \n",
    "        # Print column names to understand actual data structure\n",
    "        print(f\"Columns in {metric} dataset:\")\n",
    "        print(df.columns.tolist())\n",
    "        \n",
    "        # Select appropriate id_vars based on actual column names\n",
    "        id_cols = [col for col in df.columns if col in ['geo', 'time', 'country', 'year']]\n",
    "        if not id_cols:\n",
    "            print(f\"Warning: No identifying columns found in {metric} dataset\")\n",
    "            continue\n",
    "            \n",
    "        # Reshape data\n",
    "        try:\n",
    "            melted = df.melt(id_vars=id_cols,\n",
    "                           var_name='indicator',\n",
    "                           value_name=metric)\n",
    "            \n",
    "            # Select required columns\n",
    "            melted = melted[id_cols + [metric]]\n",
    "            \n",
    "            # Standardize column names\n",
    "            column_mapping = {\n",
    "                'geo': 'country',\n",
    "                'time': 'year'\n",
    "            }\n",
    "            melted = melted.rename(columns=column_mapping)\n",
    "            \n",
    "            # Merge datasets\n",
    "            if processed_data.empty:\n",
    "                processed_data = melted\n",
    "            else:\n",
    "                merge_cols = ['country', 'year'] if 'country' in melted.columns else ['geo', 'time']\n",
    "                processed_data = processed_data.merge(melted, on=merge_cols, how='outer')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric} data: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Clean data by removing rows with missing values\n",
    "    processed_data = processed_data.dropna()\n",
    "    \n",
    "    # Ensure consistent column naming\n",
    "    if 'geo' in processed_data.columns:\n",
    "        processed_data = processed_data.rename(columns={'geo': 'country'})\n",
    "    if 'time' in processed_data.columns:\n",
    "        processed_data = processed_data.rename(columns={'time': 'year'})\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Execute data collection and preprocessing\n",
    "print(\"Collecting education data...\")\n",
    "education_data = collect_education_data()\n",
    "\n",
    "print(\"\\nPreprocessing data...\")\n",
    "processed_education_data = preprocess_data(education_data)\n",
    "\n",
    "# Display processed data structure\n",
    "print(\"\\nProcessed data structure:\")\n",
    "print(processed_education_data.info())\n",
    "print(\"\\nFirst few rows of processed data:\")\n",
    "print(processed_education_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic Data Analysis\n",
    "\n",
    "Perform initial analysis of education metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (0, 0)\n",
      "Available columns: []\n",
      "Error in analysis: No investment-related column found in the data\n",
      "\n",
      "Detailed data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def analyze_investment_trends(df):\n",
    "    \"\"\"\n",
    "    Analyze education investment trends over time\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Processed education data\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Trends analysis results\n",
    "    \"\"\"\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Ensure data types are correct\n",
    "    if 'time' in df.columns:\n",
    "        df['year'] = pd.to_numeric(df['time'], errors='coerce')\n",
    "    \n",
    "    # Check if education investment column exists\n",
    "    investment_cols = [col for col in df.columns if 'educ' in col.lower() or 'invest' in col.lower()]\n",
    "    if investment_cols:\n",
    "        investment_col = investment_cols[0]\n",
    "        print(f\"Using column '{investment_col}' for investment analysis\")\n",
    "    else:\n",
    "        raise ValueError(\"No investment-related column found in the data\")\n",
    "    \n",
    "    # Calculate investment trends\n",
    "    trends = df.groupby('year')[investment_col].agg(['mean', 'min', 'max']).round(2)\n",
    "    \n",
    "    # Create trend visualization\n",
    "    fig = px.line(trends.reset_index(), \n",
    "                  x='year',\n",
    "                  y=['mean', 'min', 'max'],\n",
    "                  title='Education Investment Trends',\n",
    "                  labels={'value': 'Investment Value',\n",
    "                         'year': 'Year',\n",
    "                         'variable': 'Metric'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=\"Investment (%)\",\n",
    "        legend_title=\"Statistics\"\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return trends\n",
    "\n",
    "# Analyze investment trends with error handling\n",
    "try:\n",
    "    investment_trends = analyze_investment_trends(processed_education_data)\n",
    "except Exception as e:\n",
    "    print(f\"Error in analysis: {str(e)}\")\n",
    "    print(\"\\nDetailed data information:\")\n",
    "    print(processed_education_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Analysis\n",
    "\n",
    "Perform more sophisticated analyses including quality assessment and forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_education_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quality_scores\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Analyze education quality\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m quality_scores \u001b[38;5;241m=\u001b[39m analyze_education_quality(\u001b[43mprocessed_education_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_education_data' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_education_quality(df):\n",
    "    # Normalize metrics\n",
    "    scaler = StandardScaler()\n",
    "    metrics = ['student_teacher_ratio', 'completion_rate', 'literacy_rate']\n",
    "    normalized_data = pd.DataFrame(scaler.fit_transform(df[metrics]), columns=metrics)\n",
    "    \n",
    "    # Calculate quality scores\n",
    "    weights = {'student_teacher_ratio': -0.3, 'completion_rate': 0.4, 'literacy_rate': 0.3}\n",
    "    quality_scores = sum(normalized_data[metric] * weight for metric, weight in weights.items())\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = px.box(quality_scores, title='Education Quality Score Distribution')\n",
    "    fig.show()\n",
    "    \n",
    "    return quality_scores\n",
    "\n",
    "# Analyze education quality\n",
    "quality_scores = analyze_education_quality(processed_education_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time Series Forecasting\n",
    "\n",
    "Predict future education metrics using time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_education_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Forecast education investment\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m investment_forecast \u001b[38;5;241m=\u001b[39m forecast_metrics(\u001b[43mprocessed_education_data\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meducation_investment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_education_data' is not defined"
     ]
    }
   ],
   "source": [
    "def forecast_metrics(df, metric, periods=5):\n",
    "    # Prepare time series data\n",
    "    ts_data = df.groupby('year')[metric].mean()\n",
    "    \n",
    "    # Fit model\n",
    "    model = ExponentialSmoothing(ts_data, seasonal_periods=4, trend='add', seasonal='add')\n",
    "    fitted_model = model.fit()\n",
    "    \n",
    "    # Generate forecast\n",
    "    forecast = fitted_model.forecast(periods)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=ts_data.index, y=ts_data.values, name='Historical'))\n",
    "    fig.add_trace(go.Scatter(x=forecast.index, y=forecast.values, name='Forecast'))\n",
    "    fig.update_layout(title=f'{metric} Forecast')\n",
    "    fig.show()\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "# Forecast education investment\n",
    "investment_forecast = forecast_metrics(processed_education_data, 'education_investment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions and Recommendations\n",
    "\n",
    "Summarize key findings and provide recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_education_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recommendations\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Generate recommendations\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m generate_recommendations(\u001b[43mprocessed_education_data\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRecommendations:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_education_data' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_recommendations(df):\n",
    "    recommendations = []\n",
    "    \n",
    "    # Analyze investment efficiency\n",
    "    inv_corr = df['education_investment'].corr(df['completion_rate'])\n",
    "    if inv_corr > 0.5:\n",
    "        recommendations.append(\"Increase education investment to improve completion rates\")\n",
    "    \n",
    "    # Analyze quality metrics\n",
    "    quality_trend = df.groupby('year')['completion_rate'].mean().pct_change().mean()\n",
    "    if quality_trend < 0:\n",
    "        recommendations.append(\"Focus on improving education quality metrics\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = generate_recommendations(processed_education_data)\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in recommendations:\n",
    "    print(f\"- {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
