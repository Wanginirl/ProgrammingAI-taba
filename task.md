选题与研究问题（RQ）制定

从主题中选择一个领域（如健康、金融、环境等）。
明确研究问题（RQ），例如“教育投入是否显著促进经济增长？”。
选题需要能够通过数据分析解决。
数据集选择

每位成员选择一个独立的数据集，至少包含一个非结构化/半结构化数据集。
数据格式：XML、JSON、图片等。
公共字段：如国家、日期、类别等，用于数据集整合。
确保数据集的规模足够（每个数据集至少 1000 条记录）。
数据存储

将数据存储在合适的数据库中：
结构化数据：PostgreSQL。
非结构化数据：MongoDB。
数据存储需通过编程实现（Python 等）。
数据清洗与预处理

清理数据（如去重、填补缺失值）。
转换数据格式，使其适合分析（如时间格式标准化、字段命名一致性）。
储存清洗后的数据，供后续分析使用。
数据分析与可视化

每位成员独立分析自己的数据集：
使用 Python 或可视化工具（如 Matplotlib、Seaborn）创建图表：
直方图：显示数据分布。
散点图：分析变量间的关系。
相关性热图：探索变量间的相关性。
团队整合数据后，分析整体模式和趋势。
整合数据并回答研究问题

使用公共字段合并团队成员的数据集。
根据整合后的数据回答研究问题（RQ）。
得出分析结论，探讨数据中的关键模式和趋势。
（可选）应用 AI/ML 技术

如果数据适用，应用预训练模型（如 BERT、ResNet）进行分类、聚类或回归分析。
分析模型的输出结果，为研究问题提供支持。
提交报告与展示

撰写项目报告，包含以下内容：
引言：背景与研究问题。
方法：数据选取、清洗、分析过程。
结果：可视化和分析结论。
结论与未来工作：总结关键发现和建议。
创建视频展示（10 分钟），每位成员需参与并解释工作内容。
提交代码和个人日志，记录任务执行情况。
核心要求提炼
数据相关：

至少一个数据集为非结构化/半结构化。
数据集包含公共字段，用于整合。
每个数据集至少 1000 条记录。
技术与工具：

使用 Python 编程完成数据库连接、数据清洗与分析。
数据存储在适当的数据库中（MongoDB 或 PostgreSQL）。
分析与可视化：

每位成员独立完成一个数据集的分析。
生成直方图、散点图、热图等，解释关键模式。
整合与回答问题：

团队合并数据集并回答研究问题（RQ）。
提供洞察和结论。
成果提交：

IEEE 格式的报告（约 3500 字）。
代码文件和个人日志。
项目展示视频（团队合作完成）。
任务优先级
明确选题和研究问题（优先级最高）。
获取并清洗数据集。
完成数据库存储与预处理。
各自完成数据分析与可视化。
整合分析结果，撰写报告与展示。
通过以上任务拆解和核心要求的提炼，可以高效完成项目并确保满足评分标准。


目基本信息
课程信息：
课程名称：Programming for Artificial Intelligence (H9PAI)
学校：National College of Ireland
项目权重：70%
提交截止：2024年12月18日 23:55
项目目标
核心目标：
使用AI解决方案相关的编程技术进行数据分析和可视化
处理复杂和半结构化数据
应用AI相关的预处理和可视化技术
团队要求：
团队规模：2-3人
每个成员至少选择一个数据集进行分析
技术要求
数据集要求：
每个数据集至少1000条记录
支持的数据格式：XML、JSON、网络爬虫数据等
推荐数据源已在文档中列出（如data.gov、data.worldbank.org等）
数据存储：
半结构化数据推荐使用MongoDB
结构化数据可使用PostgreSQL
必须以编程方式存储数据
数据处理与可视化：
数据预处理：清洗、转换
可视化要求：
直方图/箱线图：展示关键特征分布
散点图：分析数值特征关系
条形图：分析分类数据
相关性热力图：展示数值特征间关系
可选AI模型应用：
可使用预训练模型（无需从头训练）
示例：
文本数据：使用BERT进行情感分析
图像数据：使用ResNet或VGG16进行分类
提交要求
项目报告（约3500字）：
遵循IEEE格式
主要章节：
摘要
引言
相关工作
方法论
结果与评估
结论与未来工作
参考文献
项目演示：
10分钟视频展示
每个团队成员都要能独立展示所有内容
代码提交：
打包所有项目资产（代码、数据、配置）
项目日志：
记录项目进展
评估目标
项目将评估以下学习目标：

分析和评估AI解决方案实现中常用的编程语言和环境
评估实现AI解决方案的挑战
评估软件开发方法和实践
使用关键算法、数据结构和相关编程语言实现AI解决方案


数据集的具体要求：
至少包含一个非结构化/半结构化数据集：

格式可以是 XML、JSON 或图片等非结构化格式。
数据来源需要具备一定的复杂性，不能过于简单。
公共字段：

数据集需要有一个公共键（如国家、日期、类别等），以便后续进行数据整合。
这些字段用于连接团队成员选择的数据集。
数据规模：

每个数据集应至少包含 1000 条记录，确保有足够的样本进行分析。
存储要求：

结构化数据：推荐存储在 PostgreSQL。
非结构化数据：推荐存储在 MongoDB 或其他适合非结构化数据的数据库。
预处理和转换：

数据需要经过清洗、格式化和转换。
数据清洗操作包括去除缺失值、处理重复值和格式标准化。
个体与团队任务分工：

每位成员选择一个独立的数据集进行分析。
合并数据集时，回答研究问题（RQ）。
可视化分析：

需要生成直方图、散点图、相关性热图或其他相关可视化图表，用于解释数据中的模式和趋势。
（可选）应用 AI/ML 模型：

如果数据适合，可以应用预训练的机器学习或深度学习模型，例如分类、聚类或回归。
项目执行框架：
每位成员选择一个符合要求的数据集。
使用 Python 编程完成以下任务：
数据库连接与数据存储。
数据清洗与转换。
初步分析与可视化。
将团队成员的数据整合，通过公共字段进行合并。
生成最终可视化，并根据研究问题给出分析结论。


# 对数据集要求：

### **数据集要求总结**
1. **团队成员数**：
   - 每个团队成员至少需要选择一个数据集。

2. **数据类型**：
   - 至少包含一个**非结构化或半结构化数据集**，如 XML、JSON、图片等格式。

3. **公共键**：
   - 数据集中需包含一个**公共字段**，用于后续的数据连接（例如：国家、位置、日期等）。

4. **数据存储**：
   - 将非结构化或半结构化数据存储到适当的数据库中（如 MongoDB）。
   - 确保数据的组织和可用性。

5. **数据预处理**：
   - 使用 Python 连接数据库，并执行数据清洗、转换和预处理操作。

6. **个体分析**：
   - 每个团队成员对自己的数据集进行独立分析。

7. **数据整合与问题回答**：
   - 合并所有数据集，通过整合后的数据回答初始研究问题（RQ）。

8. **（可选）机器学习/深度学习应用**：
   - 如果数据允许，可以应用 ML/DL 技术（如回归、分类、聚类等）进行更深入的分析。

---

### **关键点**
- **非结构化数据的引入**：至少一个数据集必须是 XML、JSON 或图片等格式。
- **公共字段的设置**：选择的数据集需要有一致的字段（例如“国家”或“年份”），以确保可整合。
- **数据库选择**：非结构化数据建议存储到 MongoDB，确保高效查询和操作。


基础统计分析
时间序列分析
相关性分析
可视化图表生成

进行时间序列分析，观察这些指标的变化趋势
研究不同指标之间的相关性
创建可视化图表来展示关键发现
