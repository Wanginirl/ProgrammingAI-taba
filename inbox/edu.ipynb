{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75af7a18-0b32-45e1-ac56-43f9787f38ec",
   "metadata": {},
   "source": [
    "# Education Data Analysis Project\n",
    "\n",
    "## Overview\n",
    "This project presents a comprehensive analysis of education data across different countries. The analysis combines data from multiple sources to examine education investment, quality, outcomes, and resource allocation patterns.\n",
    "\n",
    "### Project Objectives\n",
    "1. Analyze education investment trends\n",
    "2. Evaluate education quality indicators\n",
    "3. Assess resource allocation efficiency\n",
    "4. Predict future education metrics\n",
    "\n",
    "### Analysis Components\n",
    "- Data collection from Eurostat\n",
    "- Statistical analysis\n",
    "- Time series forecasting\n",
    "- Interactive visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d72c52-f916-48f1-b2ff-c2ccf385b40b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's import all necessary packages and set up configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0387714-6963-4e74-9458-6462e18ea9e2",
   "metadata": {},
   "source": [
    "##  Environment Installation\n",
    "\n",
    "Before starting the analysis, we need to install the required packages. Run the following commands in your terminal or in a notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ea77fa-5e34-43aa-8f46-b1db1e674305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: plotly in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (5.24.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: statsmodels in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (0.14.4)\n",
      "Requirement already satisfied: pymongo in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (4.6.0)\n",
      "Requirement already satisfied: psycopg2-binary in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.9.10)\n",
      "Requirement already satisfied: python-dotenv in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: eurostat in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from plotly) (24.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pymongo) (2.6.1)\n",
      "Requirement already satisfied: requests in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from eurostat) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stark/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->eurostat) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "pandas: v2.1.3\n",
      "numpy: v1.24.3\n",
      "plotly: v5.24.1\n",
      "scikit-learn: v1.3.2\n",
      "statsmodels: v0.14.4\n",
      "pymongo: v4.6.0\n",
      "psycopg2-binary: v2.9.10\n",
      "python-dotenv: v1.0.0\n",
      "eurostat: v1.0.4\n",
      "tqdm: v4.66.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/6qgmz73j6lx3gzkfjw5151nh0000gn/T/ipykernel_63881/958489629.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy plotly scikit-learn statsmodels pymongo psycopg2-binary python-dotenv eurostat tqdm\n",
    "\n",
    "# Verify installations\n",
    "import pkg_resources\n",
    "required_packages = [\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'plotly',\n",
    "    'scikit-learn',\n",
    "    'statsmodels',\n",
    "    'pymongo',\n",
    "    'psycopg2-binary',\n",
    "    'python-dotenv',\n",
    "    'eurostat',\n",
    "    'tqdm'\n",
    "]\n",
    "\n",
    "# Check installed versions\n",
    "for package in required_packages:\n",
    "    version = pkg_resources.get_distribution(package).version\n",
    "    print(f\"{package}: v{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187c4072-8252-4725-9dca-6fb9b727ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import eurostat\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='education_data_collection.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e680dc-9e38-400d-96d2-646b3ea63a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='education_data_collection.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Database Configuration\n",
    "load_dotenv()\n",
    "\n",
    "# PostgreSQL configuration\n",
    "POSTGRES_CONFIG = {\n",
    "    'dbname': os.getenv('POSTGRES_DB', 'education_db'),\n",
    "    'user': os.getenv('POSTGRES_USER'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD'),\n",
    "    'host': os.getenv('POSTGRES_HOST'),\n",
    "    'port': os.getenv('POSTGRES_PORT')\n",
    "}\n",
    "\n",
    "# MongoDB configuration\n",
    "MONGODB_HOST = os.getenv('MONGODB_HOST')\n",
    "MONGODB_PORT = int(os.getenv('MONGODB_PORT'))\n",
    "MONGODB_USER = os.getenv('MONGODB_USER')\n",
    "MONGODB_PASSWORD = os.getenv('MONGODB_PASSWORD')\n",
    "MONGODB_DB = os.getenv('MONGODB_DB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3cf0eb-9fe4-4bcc-b2a2-059c0f11db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Database Connection Functions\n",
    "def get_postgres_connection():\n",
    "    \"\"\"Get PostgreSQL connection with retry mechanism\"\"\"\n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=os.getenv('POSTGRES_DB'),\n",
    "                user=os.getenv('POSTGRES_USER'),\n",
    "                password=os.getenv('POSTGRES_PASSWORD'),\n",
    "                host=os.getenv('POSTGRES_HOST'),\n",
    "                port=os.getenv('POSTGRES_PORT'),\n",
    "                connect_timeout=30  # Increase timeout to 30 seconds\n",
    "            )\n",
    "            print(\"Successfully connected to PostgreSQL\")\n",
    "            return conn\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retry_count + 1} failed: {str(e)}\")\n",
    "            retry_count += 1\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(2)  # Wait 2 seconds before retrying\n",
    "    \n",
    "    print(\"Failed to connect to PostgreSQL after all retries\")\n",
    "    return None\n",
    "\n",
    "def get_mongodb_connection():\n",
    "    \"\"\"Get MongoDB connection with retry mechanism\"\"\"\n",
    "    try:\n",
    "        client = MongoClient(\n",
    "            host=os.getenv('MONGODB_HOST'),\n",
    "            port=int(os.getenv('MONGODB_PORT')),\n",
    "            username=os.getenv('MONGODB_USER'),\n",
    "            password=os.getenv('MONGODB_PASSWORD'),\n",
    "            serverSelectionTimeoutMS=30000,  # Increase timeout to 30 seconds\n",
    "            connectTimeoutMS=30000,\n",
    "            retryWrites=True,\n",
    "            w='majority'\n",
    "        )\n",
    "        db = client[os.getenv('MONGODB_DB')]\n",
    "        # Test connection\n",
    "        client.server_info()\n",
    "        print(\"Successfully connected to MongoDB\")\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MongoDB: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa900e5-caa1-44cf-96e4-9856811f31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Data Processing and Storage Functions\n",
    "def process_education_data(df, metric_type):\n",
    "    \"\"\"Process education data with error handling and data validation\"\"\"\n",
    "    try:\n",
    "        # Remove any duplicate columns\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "        \n",
    "        # Basic data cleaning\n",
    "        df = df.dropna(how='all')  # Drop rows where all values are NaN\n",
    "        \n",
    "        # Convert numeric columns to float\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        for col in numeric_columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # Add metadata\n",
    "        df['metric_type'] = metric_type\n",
    "        df['processed_date'] = pd.Timestamp.now()\n",
    "        \n",
    "        # Validate data\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No valid data found for {metric_type}\")\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {metric_type} data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def store_in_mongodb(db, collection_name, records):\n",
    "    \"\"\"Store data in MongoDB with error handling and batch processing\"\"\"\n",
    "    try:\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        # Use bulk write operations for better performance\n",
    "        operations = []\n",
    "        for record in records:\n",
    "            # Create unique identifier\n",
    "            filter_dict = {\n",
    "                'country': record.get('country'),\n",
    "                'year': record.get('year'),\n",
    "                'metric_type': record.get('metric_type')\n",
    "            }\n",
    "            \n",
    "            operations.append(\n",
    "                UpdateOne(\n",
    "                    filter_dict,\n",
    "                    {'$set': record},\n",
    "                    upsert=True\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        if operations:\n",
    "            # Process in batches of 1000\n",
    "            batch_size = 1000\n",
    "            for i in range(0, len(operations), batch_size):\n",
    "                batch = operations[i:i + batch_size]\n",
    "                collection.bulk_write(batch, ordered=False)\n",
    "                \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error storing data in MongoDB: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def store_in_postgres(conn, table_name, records):\n",
    "    \"\"\"Store data in PostgreSQL with error handling\"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Convert records to list of tuples for PostgreSQL\n",
    "            values = []\n",
    "            for record in records:\n",
    "                try:\n",
    "                    values.append((\n",
    "                        str(record['country']),\n",
    "                        int(record['year']),\n",
    "                        str(record['metric_type']),\n",
    "                        float(record['value'])\n",
    "                    ))\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    print(f\"Skipping record due to conversion error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if values:\n",
    "                execute_values(cur, f\"\"\"\n",
    "                    INSERT INTO {table_name} (country, year, metric_name, metric_value)\n",
    "                    VALUES %s\n",
    "                    ON CONFLICT (country, year, metric_name) \n",
    "                    DO UPDATE SET metric_value = EXCLUDED.metric_value;\n",
    "                \"\"\", values)\n",
    "                conn.commit()\n",
    "                print(f\"Stored {len(values)} records in PostgreSQL for {table_name}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error storing data in PostgreSQL: {str(e)}\")\n",
    "        conn.rollback()\n",
    "\n",
    "def collect_eurostat_data(metric_name):\n",
    "    \"\"\"Collect education data from Eurostat with error handling\"\"\"\n",
    "    try:\n",
    "        # Define dataset codes\n",
    "        dataset_codes = {\n",
    "            'education_investment': 'educ_uoe_fine09',\n",
    "            'student_teacher_ratio': 'educ_uoe_perp04',\n",
    "            'completion_rate': 'edat_lfse_03'\n",
    "        }\n",
    "        \n",
    "        if metric_name not in dataset_codes:\n",
    "            raise ValueError(f\"Unknown metric: {metric_name}\")\n",
    "            \n",
    "        # Get dataset code\n",
    "        dataset_code = dataset_codes[metric_name]\n",
    "        \n",
    "        # Collect data from Eurostat\n",
    "        df = eurostat.get_data_df(dataset_code)\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(f\"No data found for {metric_name}\")\n",
    "            return None\n",
    "            \n",
    "        # Process the DataFrame\n",
    "        df = df.reset_index()\n",
    "        \n",
    "        # Get time column (should contain country codes)\n",
    "        time_cols = [col for col in df.columns if 'TIME' in col]\n",
    "        if not time_cols:\n",
    "            print(f\"No time column found for {metric_name}\")\n",
    "            return None\n",
    "            \n",
    "        time_col = time_cols[0]\n",
    "        \n",
    "        # Extract country from the time column\n",
    "        df['country'] = df[time_col].str.split('\\\\').str[0]\n",
    "        \n",
    "        # Get year columns (numeric columns)\n",
    "        year_cols = [col for col in df.columns if str(col).isdigit()]\n",
    "        if not year_cols:\n",
    "            print(f\"No year columns found for {metric_name}\")\n",
    "            return None\n",
    "            \n",
    "        # Create processed dataframe\n",
    "        processed_data = []\n",
    "        \n",
    "        # Process each year\n",
    "        for year in year_cols:\n",
    "            year_data = df[['country', year]].copy()\n",
    "            year_data = year_data.rename(columns={year: 'value'})\n",
    "            year_data['year'] = int(year)\n",
    "            processed_data.append(year_data)\n",
    "            \n",
    "        # Combine all years\n",
    "        result_df = pd.concat(processed_data, ignore_index=True)\n",
    "        \n",
    "        # Clean up the data\n",
    "        result_df['value'] = pd.to_numeric(result_df['value'], errors='coerce')\n",
    "        result_df = result_df.dropna(subset=['value'])\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error collecting {metric_name} data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def collect_and_store_education_data(pg_conn, mongo_db):\n",
    "    \"\"\"Collect and store education data with improved error handling\"\"\"\n",
    "    metrics = {\n",
    "        'education_investment': 'educ_investment',\n",
    "        'student_teacher_ratio': 'student_teacher',\n",
    "        'completion_rate': 'completion_rate'\n",
    "    }\n",
    "    \n",
    "    for metric_name, table_name in metrics.items():\n",
    "        try:\n",
    "            print(f\"Collecting {metric_name} data...\")\n",
    "            \n",
    "            # Collect data\n",
    "            df = collect_eurostat_data(metric_name)\n",
    "            if df is None:\n",
    "                print(f\"Skipping {metric_name} due to data collection error\")\n",
    "                continue\n",
    "            \n",
    "            # Add metadata\n",
    "            df['metric_type'] = metric_name\n",
    "            df['processed_date'] = pd.Timestamp.now()\n",
    "            \n",
    "            # Convert to records\n",
    "            records = df.to_dict('records')\n",
    "            \n",
    "            if not records:\n",
    "                print(f\"No records to store for {metric_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Store in PostgreSQL\n",
    "            try:\n",
    "                with pg_conn.cursor() as cur:\n",
    "                    values = [(\n",
    "                        str(record['country']),\n",
    "                        int(record['year']),\n",
    "                        str(metric_name),\n",
    "                        float(record['value'])\n",
    "                    ) for record in records if all(k in record for k in ['country', 'year', 'value'])]\n",
    "                    \n",
    "                    if values:\n",
    "                        execute_values(cur, f\"\"\"\n",
    "                            INSERT INTO raw_education_data (country, year, metric_name, metric_value)\n",
    "                            VALUES %s\n",
    "                            ON CONFLICT (country, year, metric_name) \n",
    "                            DO UPDATE SET metric_value = EXCLUDED.metric_value;\n",
    "                        \"\"\", values)\n",
    "                        pg_conn.commit()\n",
    "                        print(f\"Stored {len(values)} records in PostgreSQL for {metric_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error storing data in PostgreSQL: {str(e)}\")\n",
    "                pg_conn.rollback()\n",
    "            \n",
    "            # Store in MongoDB\n",
    "            try:\n",
    "                collection = mongo_db[metric_name]\n",
    "                for record in records:\n",
    "                    if all(k in record for k in ['country', 'year', 'value']):\n",
    "                        collection.update_one(\n",
    "                            {\n",
    "                                'country': str(record['country']),\n",
    "                                'year': int(record['year'])\n",
    "                            },\n",
    "                            {\n",
    "                                '$set': {\n",
    "                                    'value': float(record['value']),\n",
    "                                    'metric_type': metric_name,\n",
    "                                    'updated_at': datetime.now()\n",
    "                                }\n",
    "                            },\n",
    "                            upsert=True\n",
    "                        )\n",
    "                print(f\"Successfully stored records in MongoDB for {metric_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error storing data in MongoDB: {str(e)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric_name}: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa407b-eaa1-493d-b358-d99ff5198b76",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "\n",
    "This section collects education-related data from Eurostat, including:\n",
    "- Education investment\n",
    "- Student-teacher ratio\n",
    "- Completion rates\n",
    "- Literacy rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b40e52-f740-4f2a-88ba-b01c402b1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting education data collection...\n",
      "Collecting education_investment data...\n",
      "\n",
      "Columns in education_investment dataset:\n",
      "['freq', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Successfully collected and transformed education_investment data\n",
      "Shape of education_investment dataset: (25850, 6)\n",
      "Columns in transformed dataset: ['freq', 'unit', 'isced11', 'year', 'education_investment', 'geo']\n",
      "\n",
      "Collecting student_teacher_ratio data...\n",
      "\n",
      "Columns in student_teacher_ratio dataset:\n",
      "['freq', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
      "Successfully collected and transformed student_teacher_ratio data\n",
      "Shape of student_teacher_ratio dataset: (5960, 6)\n",
      "Columns in transformed dataset: ['freq', 'unit', 'isced11', 'year', 'student_teacher_ratio', 'geo']\n",
      "\n",
      "Collecting completion_rate data...\n",
      "\n",
      "Columns in completion_rate dataset:\n",
      "['freq', 'sex', 'age', 'unit', 'isced11', 'geo\\\\TIME_PERIOD', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Successfully collected and transformed completion_rate data\n",
      "Shape of completion_rate dataset: (214848, 8)\n",
      "Columns in transformed dataset: ['freq', 'sex', 'age', 'unit', 'isced11', 'year', 'completion_rate', 'geo']\n",
      "\n",
      "Collecting literacy_rate data...\n",
      "\n",
      "Columns in literacy_rate dataset:\n",
      "['freq', 'sex', 'wstatus', 'citizen', 'age', 'unit', 'geo\\\\TIME_PERIOD', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Successfully collected and transformed literacy_rate data\n",
      "Shape of literacy_rate dataset: (41860, 9)\n",
      "Columns in transformed dataset: ['freq', 'sex', 'wstatus', 'citizen', 'age', 'unit', 'year', 'literacy_rate', 'geo']\n",
      "\n",
      "\n",
      "Structure of education_investment dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25850 entries, 0 to 2584\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   freq                  25850 non-null  object \n",
      " 1   unit                  25850 non-null  object \n",
      " 2   isced11               25850 non-null  object \n",
      " 3   year                  25850 non-null  object \n",
      " 4   education_investment  17756 non-null  float64\n",
      " 5   geo                   25850 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "  freq unit isced11  year  education_investment geo\n",
      "0    A  EUR     ED0  2012                6313.5  AT\n",
      "0    A  EUR     ED0  2013                6579.9  AT\n",
      "0    A  EUR     ED0  2014                6893.8  AT\n",
      "0    A  EUR     ED0  2015                6959.6  AT\n",
      "0    A  EUR     ED0  2016                7267.0  AT\n",
      "\n",
      "==================================================\n",
      "\n",
      "Structure of student_teacher_ratio dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5960 entries, 0 to 595\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   freq                   5960 non-null   object \n",
      " 1   unit                   5960 non-null   object \n",
      " 2   isced11                5960 non-null   object \n",
      " 3   year                   5960 non-null   object \n",
      " 4   student_teacher_ratio  4174 non-null   float64\n",
      " 5   geo                    5960 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 325.9+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "  freq unit isced11  year  student_teacher_ratio geo\n",
      "0    A   RT     ED0  2013                   12.8  AT\n",
      "0    A   RT     ED0  2014                   12.9  AT\n",
      "0    A   RT     ED0  2015                   12.5  AT\n",
      "0    A   RT     ED0  2016                   12.3  AT\n",
      "0    A   RT     ED0  2017                   12.7  AT\n",
      "\n",
      "==================================================\n",
      "\n",
      "Structure of completion_rate dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 214848 entries, 0 to 6713\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   freq             214848 non-null  object \n",
      " 1   sex              214848 non-null  object \n",
      " 2   age              214848 non-null  object \n",
      " 3   unit             214848 non-null  object \n",
      " 4   isced11          214848 non-null  object \n",
      " 5   year             214848 non-null  object \n",
      " 6   completion_rate  124158 non-null  float64\n",
      " 7   geo              214848 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 14.8+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "  freq sex     age unit isced11  year  completion_rate geo\n",
      "0    A   F  Y15-64   PC   ED0-2  1992              NaN  AT\n",
      "0    A   F  Y15-64   PC   ED0-2  1993              NaN  AT\n",
      "0    A   F  Y15-64   PC   ED0-2  1994              NaN  AT\n",
      "0    A   F  Y15-64   PC   ED0-2  1995             41.4  AT\n",
      "0    A   F  Y15-64   PC   ED0-2  1996             39.6  AT\n",
      "\n",
      "==================================================\n",
      "\n",
      "Structure of literacy_rate dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 41860 entries, 0 to 2092\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   freq           41860 non-null  object \n",
      " 1   sex            41860 non-null  object \n",
      " 2   wstatus        41860 non-null  object \n",
      " 3   citizen        41860 non-null  object \n",
      " 4   age            41860 non-null  object \n",
      " 5   unit           41860 non-null  object \n",
      " 6   year           41860 non-null  object \n",
      " 7   literacy_rate  18756 non-null  float64\n",
      " 8   geo            41860 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "  freq sex wstatus        citizen     age unit  year  literacy_rate geo\n",
      "0    A   F     EMP  EU27_2020_FOR  Y18-24   PC  2004            NaN  AT\n",
      "0    A   F     EMP  EU27_2020_FOR  Y18-24   PC  2005            NaN  AT\n",
      "0    A   F     EMP  EU27_2020_FOR  Y18-24   PC  2006            NaN  AT\n",
      "0    A   F     EMP  EU27_2020_FOR  Y18-24   PC  2007            NaN  AT\n",
      "0    A   F     EMP  EU27_2020_FOR  Y18-24   PC  2008            NaN  AT\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def collect_education_data():\n",
    "    \"\"\"\n",
    "    Collect education data from Eurostat\n",
    "    Returns a dictionary containing different education metrics\n",
    "    \"\"\"\n",
    "    datasets = {\n",
    "        'education_investment': 'educ_uoe_fine09',  # Education investment\n",
    "        'student_teacher_ratio': 'educ_uoe_perp04', # Student-teacher ratio\n",
    "        'completion_rate': 'edat_lfse_03',          # Completion rate\n",
    "        'literacy_rate': 'edat_lfse_01'            # Literacy rate\n",
    "    }\n",
    "    \n",
    "    data = {}\n",
    "    for metric, code in datasets.items():\n",
    "        try:\n",
    "            logging.info(f\"Starting collection of {metric} data...\")\n",
    "            print(f\"Collecting {metric} data...\")\n",
    "            \n",
    "            # Get raw data from Eurostat\n",
    "            df = eurostat.get_data_df(code)\n",
    "            print(f\"\\nColumns in {metric} dataset:\")\n",
    "            print(df.columns.tolist())\n",
    "            \n",
    "            # First, handle the time columns\n",
    "            time_cols = [col for col in df.columns if col.isdigit()]\n",
    "            \n",
    "            # Identify non-time columns\n",
    "            non_time_cols = [col for col in df.columns if not col.isdigit()]\n",
    "            \n",
    "            # Create a base DataFrame with non-time columns\n",
    "            base_df = df[non_time_cols].copy()\n",
    "            \n",
    "            # Initialize list to store transformed data\n",
    "            transformed_data = []\n",
    "            \n",
    "            # Process each row\n",
    "            for idx, row in base_df.iterrows():\n",
    "                for year in time_cols:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['year'] = year\n",
    "                    new_row[metric] = df.loc[idx, year]\n",
    "                    transformed_data.append(new_row)\n",
    "            \n",
    "            # Create new DataFrame from transformed data\n",
    "            transformed_df = pd.DataFrame(transformed_data)\n",
    "            \n",
    "            # Clean the data\n",
    "            if 'geo\\\\TIME_PERIOD' in transformed_df.columns:\n",
    "                transformed_df['geo'] = transformed_df['geo\\\\TIME_PERIOD'].str.split('\\\\').str[0]\n",
    "                transformed_df = transformed_df.drop('geo\\\\TIME_PERIOD', axis=1)\n",
    "            \n",
    "            # Convert metric values to numeric\n",
    "            transformed_df[metric] = pd.to_numeric(transformed_df[metric], errors='coerce')\n",
    "            \n",
    "            # Store the transformed DataFrame\n",
    "            data[metric] = transformed_df\n",
    "            \n",
    "            print(f\"Successfully collected and transformed {metric} data\")\n",
    "            print(f\"Shape of {metric} dataset: {transformed_df.shape}\")\n",
    "            print(f\"Columns in transformed dataset: {transformed_df.columns.tolist()}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting {metric} data: {str(e)}\")\n",
    "            print(f\"Full error details: \", e)\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Execute data collection with more detailed output\n",
    "print(\"Starting education data collection...\")\n",
    "education_data = collect_education_data()\n",
    "\n",
    "# Display the structure of collected data\n",
    "for metric, df in education_data.items():\n",
    "    print(f\"\\nStructure of {metric} dataset:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ff891-6a54-4080-ada4-19e8108e8bbf",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Clean and standardize the collected data, including:\n",
    "- Merging different datasets\n",
    "- Handling missing values\n",
    "- Standardizing column names\n",
    "- Converting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a91cf-b26c-4203-9ad0-b0bc6fc837fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data preprocessing...\n",
      "Processing education_investment data...\n",
      "Processing student_teacher_ratio data...\n",
      "Processing completion_rate data...\n",
      "Processing literacy_rate data...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocess and merge all education data\n",
    "    Returns a cleaned and standardized DataFrame\n",
    "    \"\"\"\n",
    "    processed_data = None\n",
    "    \n",
    "    for metric, df in data.items():\n",
    "        print(f\"Processing {metric} data...\")\n",
    "        \n",
    "        # Determine merge columns\n",
    "        common_cols = ['geo', 'time', 'year']\n",
    "        merge_cols = [col for col in common_cols if col in df.columns]\n",
    "        \n",
    "        if not merge_cols:\n",
    "            print(f\"Warning: No merge columns found in {metric} dataset\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare current dataset\n",
    "        cols_to_keep = merge_cols + [metric]\n",
    "        current_df = df[cols_to_keep].copy()\n",
    "        \n",
    "        # Merge data\n",
    "        if processed_data is None:\n",
    "            processed_data = current_df\n",
    "        else:\n",
    "            processed_data = processed_data.merge(\n",
    "                current_df,\n",
    "                on=merge_cols,\n",
    "                how='outer'\n",
    "            )\n",
    "    \n",
    "    if processed_data is not None:\n",
    "        # Clean and standardize data\n",
    "        processed_data = processed_data.dropna()\n",
    "        processed_data['year'] = pd.to_numeric(processed_data['year'])\n",
    "        processed_data = processed_data.rename(columns={'geo': 'country'})\n",
    "        processed_data = processed_data.sort_values('year')\n",
    "        \n",
    "        print(\"Data preprocessing completed\")\n",
    "    else:\n",
    "        print(\"Warning: No valid data after preprocessing\")\n",
    "        processed_data = pd.DataFrame()\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Execute data preprocessing\n",
    "print(\"\\nStarting data preprocessing...\")\n",
    "processed_education_data = preprocess_data(education_data)\n",
    "\n",
    "# Display processed data structure\n",
    "print(\"\\nProcessed data structure:\")\n",
    "print(processed_education_data.info())\n",
    "print(\"\\nData preview:\")\n",
    "print(processed_education_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37740d29-3e66-476f-ac37-bf1bf6d9d343",
   "metadata": {},
   "source": [
    "## 4. Data Analysis\n",
    "\n",
    "Perform multi-dimensional analysis on preprocessed data:\n",
    "- Basic statistical analysis\n",
    "- Trend analysis\n",
    "- Country comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88937c2c-da82-45ea-af4c-abbb5f79c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_education_metrics(df):\n",
    "    \"\"\"\n",
    "    Analyze education indicators\n",
    "    Returns a dictionary containing analysis results and visualizations\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Basic statistical analysis\n",
    "    print(\"Performing basic statistical analysis...\")\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        if column != 'year':\n",
    "            stats = df.groupby('year')[column].agg(['mean', 'std', 'min', 'max'])\n",
    "            results[f'{column}_stats'] = stats\n",
    "            print(f\"\\nBasic statistics for {column}:\")\n",
    "            print(stats)\n",
    "    \n",
    "    # Trend analysis\n",
    "    print(\"\\nPerforming trend analysis...\")\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        if column != 'year':\n",
    "            fig = px.line(df.groupby('year')[column].mean().reset_index(),\n",
    "                         x='year', y=column,\n",
    "                         title=f'Trend of {column} Over Time')\n",
    "            results[f'{column}_trend'] = fig\n",
    "            fig.show()\n",
    "    \n",
    "    # Country comparison\n",
    "    print(\"\\nPerforming country comparison...\")\n",
    "    latest_year = df['year'].max()\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        if column != 'year':\n",
    "            latest_data = df[df['year'] == latest_year].sort_values(column, ascending=False)\n",
    "            fig = px.bar(latest_data.head(10),\n",
    "                        x='country', y=column,\n",
    "                        title=f'Top 10 Countries - {column} ({latest_year})')\n",
    "            results[f'{column}_comparison'] = fig\n",
    "            fig.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Execute data analysis\n",
    "print(\"Starting data analysis...\")\n",
    "analysis_results = analyze_education_metrics(processed_education_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5b72e-d7cc-4b8f-9b4c-774eff40708b",
   "metadata": {},
   "source": [
    "## 5. Forecasting Analysis\n",
    "\n",
    "Perform time series forecasting on education metrics:\n",
    "- Using SARIMA models\n",
    "- Generate 5-year predictions\n",
    "- Visualize forecast results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcde782-837e-4706-a75e-28fc0e4313cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
